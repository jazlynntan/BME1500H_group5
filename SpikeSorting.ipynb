{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For filtering, spike detection and sorting to obtain single unit activity (discard MUAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 300  # Low cutoff frequency in Hz\n",
    "highcut = 6000  # High cutoff frequency in Hz\n",
    "fs = 12500  # Sampling frequency in Hz\n",
    "window_size = 25  # half of what the algorithm looks at when clustering\n",
    "n_components = 3  # number of PCA components\n",
    "cluster_numbers = [i for i in range(2,6)]\n",
    "data_dir = 'path_to_data'\n",
    "\n",
    "figure_idx = 0\n",
    "fig, axes = None, None\n",
    "\n",
    "results_dict = {'neuron_' + str(i) :None for i in range(1,360+1)}\n",
    "peaks_dict = {'neuron_' + str(i) :None for i in range(1,360+1)}\n",
    "clusters_dict = {'neuron_' + str(i) :None for i in range(1,360+1)}\n",
    "\n",
    "for neuron in range(1,360+1):\n",
    "    file = os.path.join('/Users/jazlynn/Downloads/neurons-csv-format','neuron_' + str(neuron).zfill(3) + '.csv')\n",
    "    if os.path.exists(file):\n",
    "        data = pd.read_csv(file)\n",
    "        filtered_data = butter_bandpass_filter(data['Voltage'], lowcut, highcut, fs)\n",
    "        spike_peaks, _ = find_peaks(-filtered_data, height=-np.percentile(filtered_data,0.7))\n",
    "        \n",
    "        spike_waveforms = []\n",
    "        edge_peak_list = []\n",
    "        for n_peak,peak in enumerate(spike_peaks):\n",
    "            if peak - window_size >= 0 and peak + window_size < len(filtered_data):\n",
    "                spike_waveforms.append(filtered_data[peak - window_size: peak + window_size])\n",
    "            else:\n",
    "                edge_peak_list.append(n_peak)\n",
    "                \n",
    "        if edge_peak_list:\n",
    "            spike_peaks = np.delete(spike_peaks, edge_peak_list)\n",
    "            # print('edge spikes present')\n",
    "            \n",
    "        peaks_dict['neuron_' + str(neuron)] = spike_peaks\n",
    "        spike_waveforms = np.array(spike_waveforms)\n",
    "\n",
    "        # Apply PCA for dimensionality reduction\n",
    "        pca = PCA(n_components=n_components)\n",
    "        waveform_features = pca.fit_transform(spike_waveforms)\n",
    "\n",
    "        si_score = []\n",
    "        for n_clusters in cluster_numbers:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
    "            cluster_labels = kmeans.fit_predict(waveform_features)\n",
    "            si_score.append(silhouette_score(waveform_features, cluster_labels, metric='euclidean'))\n",
    "            \n",
    "        opt_n_clusters = cluster_numbers[np.argmax(si_score)]\n",
    "        # print(opt_n_clusters)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=opt_n_clusters, random_state=0, n_init='auto')\n",
    "        cluster_labels = kmeans.fit_predict(waveform_features)\n",
    "        clusters_dict['neuron_' + str(neuron)] = cluster_labels\n",
    "        \n",
    "        for final_cluster in range(opt_n_clusters):\n",
    "            ### Refractory violations ###\n",
    "            refractory_violation_counter = 0\n",
    "            cluster_spikes = spike_peaks[cluster_labels==final_cluster]\n",
    "            for isi in [cluster_spikes[i]-cluster_spikes[i-1] for i in range(1,len(cluster_spikes))]:\n",
    "                if isi <12.5:\n",
    "                    refractory_violation_counter = refractory_violation_counter + 1\n",
    "            \n",
    "            if refractory_violation_counter > 0:        \n",
    "                print('neuron ' + str(neuron) + ' cluster ' + str(final_cluster) + ' has ' + str(refractory_violation_counter) + ' refractory violations')\n",
    "                \n",
    "            ### SNR ###\n",
    "            cluster_waveforms = spike_waveforms[cluster_labels == k]\n",
    "            mean_waveform = np.mean(cluster_waveforms, axis=0)\n",
    "            snr = (np.max(mean_waveform) - np.min(mean_waveform) )/ (np.std(mean_waveform) * 2)\n",
    "            print('SNR of neuron ' + str(neuron) + ' cluster ' + str(final_cluster) + ': ' + f'{snr:.2f}')\n",
    "\n",
    "        ### PLOTTING ###     \n",
    "        if figure_idx % 9 == 0:\n",
    "            if fig is not None:\n",
    "                    plt.tight_layout()\n",
    "                    # Save the figure\n",
    "                    fig.savefig(os.path.join('Group5_spikesorting_QC', f'figure_{figure_idx//9}.png'))\n",
    "                    plt.close(fig)\n",
    "            fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "            plt.suptitle(f'Figures {figure_idx//9 + 1}-{figure_idx//9 + 1}')\n",
    "\n",
    "        i, j = figure_idx % 9 // 3, figure_idx % 9 % 3\n",
    "        \n",
    "        for k in range(opt_n_clusters):\n",
    "            cluster_waveforms = spike_waveforms[cluster_labels == k]\n",
    "            mean_waveform = np.mean(cluster_waveforms, axis=0)\n",
    "            axes[i, j].plot([t/(fs/1000) for t in range(-window_size,window_size)],mean_waveform, label=f'{np.sum(cluster_labels==k)} spikes')\n",
    "        \n",
    "        axes[i, j].set_title('neuron ' + str(neuron))\n",
    "        axes[i, j].set_xlabel('Time (ms)')\n",
    "        axes[i, j].set_ylabel('Amplitude')\n",
    "        axes[i, j].legend()\n",
    "        figure_idx += 1\n",
    "\n",
    "# last fig\n",
    "if fig is not None:\n",
    "    plt.tight_layout()\n",
    "    # Save the last figure\n",
    "    fig.savefig(os.path.join('Group5_spikesorting_QC', f'figure_{figure_idx//9}.png'))\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
